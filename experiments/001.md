# GPU ResNet 18 overfit

This experiment explores the capacity of a ResNet 18 to completely overfit a small batch of data.

### Task
Learn to predict future states and actions from past states and actions.
One timestep is the tuple (state, action).

Note:
- The game is Settlers Of Catan (SOC)
- The history length is 16
- The future length is 4
- Input and output states are represented as a tensor of size `[batch_size, seq * (C_s + C_a), H, W]`

### Hypothesis
A ResNet 18 can learn the raw data mapping between past and future states for a small amount of data.
The data is generated from a fixed simulator of the SOC game with a fixed set of 4 robot players.
We try to learn the mapping using a MSE loss (no specialization based on the type of inputs).

### Results
The hypothesis is false.

The learning is indeed happening but the current network barely improves on the chance for some states part. I believe this is due to the fact that the (state, action) tuple is very sparse and contains a lot of 0. The network will then achieve quite a high accuracy by predicting zero everywhere for those parts.
Investigation shows that it is the case, the network learns to predict only zeros for the sparse parts. It also struggles to learn to auto encode the map.

To address those issues:
- For actions, I will replace the action's indices by the policy distribution which enables the use of the cross-entropy loss. It adds a policy head.
- Every non-spatial data will be predicted as non-spatial. This adds a non-spatial state head.
- We keep the spatial prediction head.
- Finally, for the problem of the player's pieces. Those are very sparse and their representation might not be ideal but I'll to figure out a very to learn those as is anyway. I will look into over-sampling the ones for each element.
