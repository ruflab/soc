# GPU ResNet 18 overfit

This experiment explores the capacity of a ResNet 18 to completely overfit a small batch of data when we specialize the model for different kind of data.

### Task
Learn to predict future states and actions from past states and actions.
One timestep is the tuple (state, action).

Note:
- The game is Settlers of Catan
- The history length is 16
- The future length is 4
- Input are represented as a tensor of size: `[batch_size, seq * (C_s + C_a), H, W]`
- Outputs are represented as a tuple: `([batch_size, seq * C_s, H, W], [batch_size, seq, C_a])`

### Hypothesis
A ResNet 18 can learn the raw data mapping between past and future states for a small amount of data.
The data is generated from a fixed simulator of the SOC game with a fixed set of 4 robot players.
The input is kept as is but the output is separated per types (categorical, binary, float, etc.)

### Results
The results are much better with multiple heads for different predictions. But the network still struggles to learn values addressed with a regression task.
I need to explore this in details.

#### Notes:
I've explored the L2 regularisation. As it is known, the original adam implementation has trouble with L2 reg. This is why AdamW has been created. Used in conjunction with AMSgrad, it allows me to regularize and keep the same learning curve. It also seems to accelerate learning but does not solve the regression problems.

##### Edit 1:
I've explored the outputs of the model. It is actually quite accurate (predicting target +-2 in general), the problem seems to be coming from the fact that the true values are very close to each other and so the network needs to predict them very accurately.

As an example, for the `devcardsleft` input, you have a segment of 0.04 to be correct which means that the squared loss must fall down under 4e-4 to ensure a good accuracy.

##### Edit 2:
After more exploration, I finally find out the problem. The hint came from the training logs which were not consistent with predictions for the different regressions. The problem was coming from BatchNorm layers.

First, as a general case, it does not work well for small batches and you need a certain amount of batches to approximate the statistics in a sufficient manner.
But even though, the training goes very well in the overfit setting, but BatchNorm completely fails for regression in evaluation mode. If I keep the BatchNorm training setting then I indeed see that my model learns absolutely everything.

The exact problem is coming from the noise introduced by having a different setting between training and evaluation: the statistics are not computed the same way during training and evaluation. This adds noise when doing a prediction and this noise is sufficient to push the model off when trying to regress.

Conclusion: I'm going to switch norms. Since regression is a generative problem, I'll look into the other possible candidates: InstanceNorm, GroupNorm and LayerNorm.

### Final conclusion
The hypothesis is true.