# GPU ResNet 18

This experiment extends the overfitting work (see 002.md) to the full training set.

### Task
Learn to predict future states and actions from past states and actions.
One timestep is the tuple (state, action).

Note:
- The game is Settlers of Catan
- The history length is 16
- The future length is 4 or 1
- Input are represented as a tensor of size: `[batch_size, seq * (C_s + C_a), H, W]`
- Outputs are represented as a tuple: `([batch_size, seq * C_s, H, W], [batch_size, seq, C_a])`

### Hypothesis
A ResNet 18 can learn the raw data mapping between past and future states up to 90% accuracy on the full training set.
The data is generated from a fixed simulator of the SOC game with a fixed set of 4 robot players.
The input is kept as is but the output is separated per types (categorical, binary, float, etc.)

### Results
The hypothesis is considered true, even though more investigation on the learning algorithm would be needed to ensure it definitely.

After training the bot on 4 training sets containing 50, 300 and finally 5000 games. The learning curve follows the known DL behaviours: more data -> better generalisation.

Results:
- 50 games: ~56% accuracy
- 300 games: ~68% accuracy (+12%)
- 5000 games: ~80% accuracy (+12%)
If this trend continues, we can hope to reach 90% accuracy for 50000 games. But at this point, it would be hard to know if we actually poisoned the validation set: we might have seen all possible initial states etc.

One thing to note with the current data. 3 of the bots are instances of a RandomForest bot and only one is a STAC agent from StacSettlers.
I need to improve the training set data to ease the analysis.

#### Moving forward
My original goal is to study grounded language learning and not the predictive capacity in itself. The prediction task is just a way to let emerge interesting representation in the network and then check that language improves those representations.
This is why I'm going to shift my focus on improving the training set data and insert chat negotiations instead of chasing better accuracy.
